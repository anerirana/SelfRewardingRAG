import torch
import torch.nn as nn
from transformers import T5Tokenizer, T5ForConditionalGeneration

# Utilities
def exists(val):
    return val is not None

def default(val, default_value):
    return val if exists(val) else default_value

class RAGModel(nn.Module):
    def __init__(self, model_name):
        super(RAGModel, self).__init__()
        '''Retrival Augmented Generation model to generate responses for a given query 
        and a set of retieved documents
        '''
        self.tokenizer = T5Tokenizer.from_pretrained(model_name)
        self.model = T5ForConditionalGeneration.from_pretrained(model_name, device_map="auto", torch_dtype=torch.float16)

    def forward(self, prompt):
        '''Generate response for the given prompt

        Parameters:
        -----------
        prompt
            The prompt used as input to the generative model.
            Could be a RAG or QA or reward prompt.
        '''
        input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids.to("cuda")
        outputs = self.model.generate(input_ids)

        return self.tokenizer.decode(outputs[0])

    def train(self, training_dataset, batch_size=32, num_epochs=3):
        '''Train the RAGModel on the given training_dataset

        Parameters:
        -----------
        training_dataset
            Contains the training data for query augemntation or reward generation or answer generator
        '''
        
        pass

class RAGPipeline:
    def __init__(self, config: dict):
        '''Executes each block of RAGPipeline to train query augmentation and RAG models

        Parameters:
        -----------
        qa_prompt
            The query augmentation prompt template to generate n-1 similar queries to a given query
        rag_prompt
            The prompt template to use for generating responses
        reward_prompt
            The prompt template to self reward responses generated by the RAGModel
        num_documents
            Numnber of docuemts to retrieve per query by the Document Retrieval Model 
        '''
        self.rag_prompt = default(config.get('QAPrompt'), 'Default Prompt')
        self.reward_prompt = default(config.get('RewardPrompt'), 'Default Prompt')
        self.qa_prompt = default(config.get('QAPrompt'), 'Default Prompt')
        self.num_documents = default(config.get('NumberOfRetrievedDocuments'), 'Default Prompt')

    def train(self, original_query):
        '''Executes a training loop of the RAGPipeline

        Parameters:
        -----------
        original_query
            The original query to generate responses for
        '''
        # Create instances of required models
        # rag_model = RAGModel()
        # responses = rag_model(original_query, documents)

        # document_retrieval_model = DocumentRetrievalModel()
        # # TODO:Implement for loop to get k documents
        # documents = document_retrieval_model(aug_queries) 


        # # Create an instance of PreferencePairGenerator
        # pp_generator = PreferencePairGenerator(responses)

        # # Generate preference pairs
        # first_pp = pp_generator.generateFirstPP(self.rag_prompt, None, None)  
        # second_pp = pp_generator.generateSecondPP(self.reward_prompt, None) 

        # # Train the RAG Model with the first preference pair
        # rag_model.train(first_pp)


class PreferencePairGenerator:
    def __init__(self, rag_model: RAGModel):
        '''Generate preference pairs for a training loop of RAG pipeline

        Parameters:
        -----------
        rag_model
            RAG model to generate responses and corresponding rewards
        '''
        self.rag_model = rag_model

    def generateFirstPP(self, query, docs, responses):
        '''Generates the first preference pair matrix
        '''
        return []  # Placeholder for a matrix

    def generateSecondPP(self, org_query, response):
        '''generate the second preference pair matrix
        '''
        return []  # Placeholder for another matrix