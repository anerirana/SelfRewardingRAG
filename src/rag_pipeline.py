import numpy as np

from llm import LLM
from document_retriver import DocumentRetrievalModel 
from constants import *
from testing_rewards import *
from preference_pair_generator import PreferencePairGenerator

# Utilities
def exists(val):
    return val is not None

def default(val, default_value):
    return val if exists(val) else default_value


class RAGPipeline:
    def __init__(self, config: dict):
        '''Executes each block of RAGPipeline to train query augmentation and RAG models

        Parameters:
        -----------
        qa_prompt_template
            The query augmentation prompt template to generate n-1 similar queries to a given query
        rag_prompt_template
            The prompt template to use for generating responses
        reward_prompt_template
            The prompt template to self reward responses generated by the RAGModel
        num_documents
            Numnber of docuemts to retrieve per query by the Document Retrieval Model 
        '''
        self.reward_prompt_template = default(config.get('RewardPromptTemplate'), 'Default Prompt')
        self.num_documents = default(config.get('NumberOfRetrievedDocuments'), 5)
        self.m = default(config.get('NumberOfQuerySets'), 1)
        self.n = default(config.get('NumberOfAugementedQueries'), 5)
        self.l = default(config.get('NumberOfSampledResponses'),5)
        self.base_model = default(config.get('BaseModel'), 'google/flan-t5-xxl')

    def train(self, original_query):
        '''Executes a training loop of the RAGPipeline

        Parameters:
        -----------
        original_query
            The original query to generate responses for
        '''
        # Create instances of required models
        language_model = LLM(self.base_model)
        document_retrieval_model = DocumentRetrievalModel()   
        pp_generator = PreferencePairGenerator(language_model)

        aug_queries = []
        all_documents = []
        top_documents = []
        all_responses = np.asarray([])
        all_rewards = np.asarray([])
        contributing_documents = {}
        first_pps = []

        for i in range(self.m):
            # queries = self.extract_query_samples(language_model, original_query, n=self.n)

            # top_k_docs, all_docs = document_retrieval_model.forward(queries)

            rag_prompt = RAG_PROMPT.format(original_query = original_query, documents = extracts)

            # #TODO: Need to sample from the language model to get l answers
            responses = []

            for j in range(self.l):
              r = language_model.forward(rag_prompt)
              print(r)
            #   r = r.split(rag_prompt)[-1].replace("<s>", "").replace("</s>", "").replace("<pad>", "")
              responses.append(r)
            
            # print(responses)
            # print(len(responses))           
            # contri_docs=[top_k_docs*5]
            # print(len(contri_docs))
            # print(len(contri_docs[0]))

            # responses, contri_docs = self.parser(responses,i)
                 
            # rewards = [language_model(self.create_reward_prompt_template(response)) for response in responses.keys]

            # pp1 = pp_generator.generateFirstPP(rag_prompt, responses.keys, rewards)

            # first_pps.append(pp1)
            # aug_queries.append(queries)
            # all_documents.append(all_docs)
            
            # top_documents.append(top_k_docs[0])
        #     all_responses = np.vstack((all_responses, responses))
        #     all_rewards = np.vstack((all_rewards, rewards))
        #     contributing_documents.update(contri_docs)
        
        # pp2 = pp_generator.generateSecondPP(self.qa_prompt_template.format(original_query), aug_queries, all_documents, top_documents, all_rewards, contributing_documents)
        
        #TODO: load pp1 and pp2 in a dataset loader for training
        # language_model.train()
        

        
        
            
    def parser(self, responses, index):
        return {}
    
    def create_reward_prompt_template(self, response):
        return ''
    
    def extract_query_samples(self, language_model, original_query, n=5):
        '''
        Extracts query samples from the language model
        '''

        qa_prompt = QUERY_AUGMENTATION_PROMPT.format(n=n, original_query=original_query)
        max_tries = 5
        response = ""
        j = 0
        sanity_check = False

        while j < max_tries and sanity_check == False:
            j += 1
            response = language_model.forward(qa_prompt)
            print(response)
            sanity_check = True
            for i in range(1, n+1):
                if f"{i}." not in response or f"{i})" not in response:
                    sanity_check = False
                    break
        
        queries = response.split(qa_prompt)[-1] #Remove the prompt from the response
        queries = queries.replace("<s>", "").replace("</s>", "").replace("<pad>", "") #Remove special tokens
        
        for i in range(1, n+1):
            queries = queries.replace(f"{i}.", "")
            queries = queries.replace(f"{i})", "")
        
        queries = queries.strip().split("\n") #Split the response into a list of queries
        #todo sanity check size of queries
        return queries
